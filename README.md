# 개발자 면접 준비

여러 회사의 기술 먼접을 보면서 공통으로 나왔던 질문을 정리합니다


## 공통 질문

<details>
<summary>자기소개</summary>

최근까지지 성과 관리 sass 개발하였고 주로 aws환경 python으로 제품 유지보수 고도화하였습니다

제품을 만드는 메이커로써 고객 불편사항, 세일즈 미팅 후기를 참고하여 여러 아이디어를 시도하여 제품을 개선하였습니다
또한 내부 도구를 만들어 동료, 팀의 업무 효율성을 높였습니다

문제 해결을 위해 필요하다면 기술 영역을 구분하지 않고 기여합니다
데이터 수집, 전처리, 시각화, 업무 자동화 영역도 경험하였고
백엔드 엔지니어로서는 안정적인 시스템 운영, 성능 최적화를 진행하며 경력을 쌓아왔습니다
</details>

<details>
<summary>지원 이유</summary>

리셀 도메인에서 유의미한 성과를 만들고 있고 다른 영역까지 도전하는게 인상에 남았습니다
소비자로서 크림을 사용할때 현재 트렌드 상품이 무었인지 스타일 방법은 어떻게 하는지 또한 가격형성은 어떤지 알아보는 재미가 있었습니다
그런 와중 파트너 서비스 채용이 열렸고 파트너센터 백오피스 개발, 업무 자동화, 대량 데이터 처리등 제 경력과 맞는 부분이 있다고 생각하여 지원하였습니다
</details>

<details>
<summary>퇴사 이유</summary>

최근 조직에서 구성원과 시너지도 좋앗고 담당 프로젝트도 재미잇게 작업하엿습니다
그러나 급격한 투자환경 변화로 제품 로드맵 진행이 중단되엇고 조직 개편이 이뤄졌습니다
잔류와 희망퇴직 선택지가 잇었습니다
이또한 개인적으로는 좋은 기회가 되리라 긍정적으로 생각하고 더 많은 경험을 해볼수있겠다 생각하여 희망퇴직을 신청하여 퇴사하였습니다
</details>

<details> 
<summary>회사를 선택하는 기준</summary>

어떤 문제를 해결하는지, 그 문제에 공감할수 있어야 합니다. 
그 다음으로 비즈니스 안정성과 기업문화를 살펴봅니다
비즈니스가 지속할수 잇는 상태인지, 비즈니스 지속을 위해 어떤 방식으로 일하는지를 기준으로 생각합니다
</details> 

<details>
<summary>성격의 장단점은?</summary>

저의 장점은 실행력과 이에 바탕이 되는 긍정적으로 보려는 점이라 생각합니다
동료들 피드백중 긍정적인 영향을 준다와 실행력이 있다는 피드백이 잇습니다
새로운 기능을 만들거나 기능을 개선해야 할때 긍정적으로 바라보며 더 나은 방향, 여러 방법을 시도하려합니다
경험상 부정적, 냉소적으로 문제를 접근한다면 현행 유지하는 경우가 대부분이라 생각하여 의도적으로 긍정적으로 보려합니다
이런 긍정적인 생각으로 생각하는 바를 실행에 옮겨 적용해고 눈으로 보고 부족한부분 개선할 점을 찾는 편입니다
단점이라면 
우선 해보자라는 의견을 내다보니 다른 팀원들에게는 피곤한 상황이 올수 있는 점입니다
의도하지 않은 부담을 주게 됩니다
개발 스콥을 확장하게 되는 경우가 생길수 잇는데 이를 잘 조절하려 합니다
따라서 적절한 상황에서 실행력을 높여야 할때를 살펴보려하고 잇습니다. 모두가 제 마음같지 않음을 항상 생각합니다

</details>

<details>
<summary>좋은 개발자란?</summary>

제품을 만드는 큰틀에서 문제를 이해하고 근본적인 문제를 찾고 같이 논의할수 있어야 하고
- 엔지니어로서는 좋은 품질의 코드를 작성하는 것 그리고 비즈니스 상황, 리소스 상황, 로드맵을 고려해 합리적인 문제 해결 방안을 제시할 수 있어야 한다고 생각합니다
- 구성원, 동료로서는 투명하고 적극적인 커뮤니케이션으로 작업 상황, 의견, 아이디어를 적극적으로 공유하는 개발자가 좋은 개발자라 생각합니다
</details>

<details>
<summary>일하기 좋은 동료는?</summary>

긍정적인 태도와 실행력있는 태도를 가진 동료가 시너지가 좋다고 생각하고
작업 초반에 아이디어 회의및 작업 방향을 정할때 여러 내용을 다룰수 있고
작업을 진행하면서 추진력있게 작업할수 있었던게 기억이 납니다

</details>

<details>
<summary>의견 충돌시 어떻게 하나?</summary>

개인별 리포트 분석 프로젝트에서 결과를 정적파일로 만드는 작업중
정적 파일 빌드 서버를 개발 vs 정적 파일 빌드 워커로 구현할지 의견이 나뉘었습니다

팀내에서 의견이 나뉘었고 각 선택지별 장단점, 필요 리소스, 예상 작업일수 등을 파악하였고
이후 논의하여 현재 리소스를 고려하여 현실적인 방향으로 선택했습니다
즉 객관적인 판단을 내릴수 있도록 내용을 정리하고 논의하여 결정하여 의견 충돌을 해소합니다

</details>

<details>
<summary>재미있었던 프로젝트?</summary>

개인별 리포트 분석 프로젝트를 재미있게 진행했습니다
분석 과정을 설계하는 것부터 분석 시각화까지 전체 과정에 참여햇고 
백엔드 기능 구현만 주로 작업할때와 다른 재미가 있었습니다
특히 시각화 부분에서 디자이너, 프론트 엔지니어와 같이 논의하여 시각화 방안을 서로 제시하고 테스트하며 더 좋은 결과를 만들기 위한 과정이 재미있었습니다
엔지니어로서 데이터 구조에 기반하여 어떤 내용을 추가로 제공할수 있을지 
사용자로서 이해하기 쉽다고 생각하는 방향등을 제시하였습니다

이런 과정을 통해 사용자가 이해하기 쉬운 결과 화면을 만들수 있었습니다
</details>

<details>
<summary>어려웠던 프로젝트는 무엇이고 해결 방법은?</summary>

기술적으로 어렵다기 보다 진행 과정이 어려웠던 프로젝트
msa환경에서 전체 도메인을 변경해야 하는 작업이 있었습니다
각 서버별 참조하는 도메인을 모두 정리했습니다
깃헙 시크릿, aws 시크릿, 전체 코드에서 하드코딩 된 도메인, 프로젝트 환경변수 등 각 서버간 도메인 의존 관계를 정리하였습니다
도메인 변환을 위해서 새로운 도메인 처리를 위한 alb를 새로 구성하고 
의존도가 낮은 서버부터 도메인 전환작업을 진행했습니다
테스트 환경이 있었으나 실제 프로덕션 환경에서 진행할때는 장애로 이어지면 안되기 때문에 주의가 필요했습니다
혹시모를 피해를 최소화 하기위해 새벽시간에 시스템 점검 공지를 하고 진행했으며
카나리 배포를 통해 프로덕션의 테스트 계정에서 먼저 확인하였고 나머지 배포
이후 모니터링 도구를 통해 api 오류율 우선적으로 확인하였습니다

기술적으로 어려운 프로젝트는 아니지만
한번에 완료할수 없는 작업이었기에 장기간 진행했으며 장애를 발생시키지 않기위해 수차례 확인하는 과정이 심리적 부담이 컸습니다

도메인 네이밍의 중요성, 장애 최소화를 위한 대비책 마련, 인프라 작업시 현황 파악이 중요하다는 것을 다시금 깨달은 작업이었다

</details>

<details>
<summary>최근 읽은 책 및 아티클은?</summary>

AI 발전 이후 어떤 조직, 사람이 경쟁력이 있는지를 다룬 아티클을 읽었습니다
AI 발전으로 개인, 조직 간의 기술 격차는 점점 줄어들게 됩니다

따라서 실행력을 바탕으로 더 많이 실험하고 도전하는 사람, 조직이 경쟁력을 갖추게 된다는 내용이 기억에 남습니다

조직은 민첩하게 움직일 수 있는 조직, 스타트업이 유리하고 구성원이 많은 조직이라면 대대적인 개편이 필요하고 권한을 위임하여 조직내에서 민첩하게 움직일수 있는 구조를 혁신해야 합니다

개인은 기술 영역을 구분하지 않고 ai와 적극 협업하여 많은 시도를 하는 태도가 경쟁력있는 태도입니다
따라서 생각한것을 ai를 사용하여 더 많이 시도해 보려 합니다
</details>

<details>
<summary>5년, 10년 후의 모습은? 또는 목표는?</summary>

백엔드 엔지니어로서는 안정성있 서버를 만들고
시스템 설계 영역을 채워 나가려 합니다
케이스 스터디를 통해 제품들을 살펴보고 어떤 구조인지 파악합니다

제품을 만드는 사람으로서는 ai 변화를 수용하여 적극 활용하여
기술 영역을 구분하지 않고 많은 시도, 결과물을 생산하여 성과로 연결할수 있는 방법을 찾고자 합니다
5년, 10년 후에는 견고하고 안정성잇는 시스템 구조를 제안할수 있고
ai를 활용하여 문제 해결 방안을 제시할수 있는 사람이 되는게 목표입니다
</details>

<details>
<summary>AI를 실무에서 어떻게 사용중인가?</summary>

테스트 코드 작성 업무에 주로 활용했습니다
기존의 테스트 케이스에서 누락된 테스트 케이스가 있는지 확인합니다
새로운 기능 추가시 어떤 테스트 케이스를 구성해야 할지 논의합니다
</details>


<details>
<summary>속도와 품질 사이에서 적절한 밸런스를 찾는 방법은?</summary>

모두가 만족하는 품질로 제품을 만들면 좋지만 시간이 여유로운 상황이 항상잇는것은 아니기에 기준을 정합니다
70% 정도의 품질을 만족하면 제품에 반영하고 점진적으로 개선을 하고
위 내용은 팀원들과 논의하여 정합니다

</details>


<details>
<summary>트러블 슈팅 경험</summary>

Celery 기반 작업에서 메시지 소비 속도가 갑자기 느려졌던 경험이 있습니다. 배포 직후 발생했기 때문에 우선 배포와의 연관성을 확인했지만, 비즈니스 로직이나 Celery 태스크 구조는 변경된 것이 없었습니다. 배포는 유지해야 하는 상황이었기 때문에, 메시지 적체가 급격하지 않은 점을 활용해서 바스티온에서 수동 소비로 임시 대응을 진행했습니다.

그동안 원인을 단계적으로 좁혀갔습니다. 먼저 비즈니스 로직을 점검해 메시지 크기나 처리 흐름의 변화가 없는지 확인했고, 다음으로 인프라 레벨에서 워커 리소스와 네트워크 상태를 확인했지만 모두 정상 상태였습니다. 마지막으로 환경 차이를 확인하는 과정에서, 대규모 작업이 병합되면서 pipenv 의존성 패키지가 함께 업데이트되었고 Celery 관련 패키지의 기본 옵션이 변경된 버전이 반영된 것을 발견했습니다. 이 옵션 변경으로 prefetch 등 메시지 처리 방식이 달라져 소비 속도가 느려진 상태였습니다.

최종적으로 프로젝트에서 사용하는 Celery 옵션을 명시적으로 지정해 기존 처리 성능을 회복했고, 패키지 버전을 명확히 고정하는 방식으로 배포 프로세스도 개선했습니다. 이 경험을 통해 장애 발생 시 비즈니스 → 인프라 → 환경/패키지 순으로 원인을 체계적으로 좁혀가는 접근이 중요하다는 점을 다시 확인할 수 있었습니다.


</details>


<details>
<summary>일하기 어려운 사람 유형</summary>

제가 일하기 어려움을 느끼는 유형은 두 가지 정도가 있습니다.

첫 번째는 지속적으로 부정적이거나, 일에 권태감을 느껴서 “지금 꼭 해야 하나?”, “한다고 뭐가 달라지나?” 같은 태도를 보이는 경우입니다. 이런 분위기는 팀 전체의 추진력을 떨어뜨리기 때문에 협업이 쉽지 않습니다.

두 번째는 리소스나 환경을 이유로 시도 자체를 포기하는 경우입니다. 현재 여건이 빡빡해도, 조금만 조정하거나 시도해 보면 해결될 수 있는 일들이 있는데 처음부터 불가능하다고 판단해버리면 팀이 앞으로 나아가기가 어렵습니다.

다만 이런 상황에서도 저는 상대의 입장을 먼저 이해하려고 하고, 문제를 더 작은 단위로 나누거나 명확한 목표를 제시하고 일이 진행되도록 상황을 만들어가려 합니다.
결국 목표는 ‘일하기 어려운 사람’이 아니라 ‘함께 일할 수 있는 방법’을 찾는 것이라고 생각합니다.

</details>

<details>
<summary>새 기술 도입/ 제안 경험</summary>

최근에는 운영 편의성과 성능을 개선하기 위해 두 가지 기술을 도입했던 경험이 있습니다.

첫 번째는 배치 관리 방식 개선입니다. 기존에는 EventBridge의 스케줄 기능을 사용했는데, 어떤 배치가 언제 동작하는지 AWS 콘솔에 직접 들어가서 확인해야 하는 불편함이 있었습니다. 코드 레벨에서 관리가 어렵다는 점도 문제였습니다. 이를 해결하기 위해 Celery Beat를 도입해 스케줄과 배치 흐름을 코드에서 한눈에 보이도록 정리했습니다. 단, Celery Beat에는 가벼운 작업만 배치하고, 실패 시 재시도나 안정성이 중요한 작업은 기존 EventBridge를 유지하는 방식으로 역할을 분리해 안정성도 함께 확보했습니다.

두 번째는 파일 첨부 기능 개선입니다. 서버를 경유해 파일을 업로드하는 방식은 부하와 비용이 커지고, 대용량 파일 처리 시 병목도 우려되었습니다. 이를 개선하기 위해 S3 Presigned URL 방식을 적용해 클라이언트가 직접 S3에 업로드하도록 구조를 변경했습니다. 서버 부하가 크게 줄었고 업로드 속도도 안정적으로 개선되었습니다.

이 두 사례 모두 ‘신기술 적용' 자체보다, 실제 문제를 해결하고 운영 복잡도를 줄이는지 여부를 기준으로 판단해 도입한 경험입니다.

</details>





## 기술 질문

### 기초

<details> 
<summary>프로세스 스레드 차이</summary>

프로세스는 보통의 프로그램이라 생각하면 됨 각각 메모리를 독립적으로 사용함
스레드는 프로세스 안에서 실행되는 단위이며 프로세스의 메모리를 공유한다
스레드는 병렬처리에 사용되며 이때 스레드 락을 사용해서 같은 메모리에 접근시 주의가 필요하다

- 뮤텍스는 한번에 하나만 접근하게 하는 락
- 세마포어는 카운트락으로 정해진 개수의 스레드만 접근하는 구조이다
- 그외에 읽기에서는 모두가 접근가능하고 쓰기에대해서만 한번에 하나만 접근하는 락도 있다

락사용시 데드락이 발생할수 잇고 타임아웃을 적절히 설정하여 무기한 대기되는 상태를 만들지 않아야 한다
</details>

<details> 
<summary>병렬성, 동시성</summary>

- 여러 코어에서 실제로 동시에 수행되는것 cpu, 메모리 따로 사용
- 하나의 스레드에서 이벤트 루프를 통해 여러 작업이 동시에 실행하여 동시에 실행되는것 처럼 보이는것
</details> 

<details> 
<summary>블로킹, 논블로킹</summary>

동기/비동기는 "언제 결과를 받을지" (대기 vs. 나중에), 블로킹/논블로킹은 "스레드가 멈추는지" (점유 vs. 반환)
- 호출한 함수가 작업을 끝날때까지 기다리는 방식 (호출한 스레드가 작업 완료 전까지 중단)
- 함수가 바로 반환하며, 호출한쪽이 기다리지 않고 다음 작업 진행(호출한 스레드가 즉시 반환 받고 다른 일 진행)
</details> 

<details> 
<summary>동기, 비동기</summary>

- 작업이 끝나야 다음 단계로 진행함, 순차적
- 작업 완료를 기다리지 않고 다음 단계 진행, 완료 이후 콜백, 이벤트 등으로 후속 처리
</details> 

<details> 
<summary>SOLID</summary>

- 단일 책임원칙:  하나의 클래스, 함수는 하나의 책임만 있어야 한다
- 개방폐쇄: 성능 확장에는 열려있고 변경에는 다혀야함, 어떤 기능 추가시 변경이 일어나면 안된다
- 리스코프치환: 자식클래스는 부모를 대체할수 잇어야함, 부모클래스 사용되는곳에서 자식클래스가 사용할수 잇어야함
- 인터페이스 분리: 딱 필요한 내용의 인터페이스만 제공되는 형태로 인터페이스가 구성되어야 한다
- 의존성역전: 상위 모듈이 하위 모듈에 의존하면 안된다. 즉 추상화에 의존해야함, 인터페이스 사용이유

</details> 

<details> 
<summary>오버로딩, 오버라이딩</summary>

다형성으로 같은 이름의 메서드나 연산자가 다른 동작을 하도록 하는 것

- 오버라이딩: 상속된 메소드를 재정의하는것
- 오버로딩: 같은 이름의 메서드를 매개변수를 달리하여 정의하는것
</details> 


---
### 데이터베이스

<details> 
<summary> 트랜잭션</summary>

원자성 일관성 독립성 지속성
- 원자성은 모두 실패하거나 모두 성공해야 한다
- 독립성은 트랜잭션간 간섭이 일어나지 않는다. 영향을 주지않는다
- 지속성을 커밋된 내용은 계속 지속되어야 한다
- 일관성은 db 정책이 변경되지 않아야한다. 이름이 필수인 정책이 있을때 이를 위반하는 데이터 추가하려고 하면 데이터 추가는 실패하고 이름 필수값이라는 정책은 계속 유지되어야 한다
</details> 

<details> 
<summary> 인덱스 </summary>
btree b+tree, 정렬, 범위검색에 유리함
해시인덱스: 정확한 값 비교
비트맵인덱스: 카디널리티 적을때, 성별같은 데이터
풀텍스트인덱스: 엘라스틱서치와 같이 자연어 검색이 필요할때 유리
</details> 


<details> 
<summary> select 쿼리 지연시 확인사항 </summary>

explain analysis를 사용하여 실행 계획을 확인한다
- type컬럼에서 all인지 등을 확인하여 풀스캔 되는지 확인한다. ref, const 등이 이상적
- rows 컬럼 확인하여 스캔 행수를 확인하고 높으면 비효율적
- key를 확인하여 선택된 인덱스가 무엇인지 확인합니다
- using filesort 정렬이 메모리/디스크에서 처리되는것
- using temporary 임시테이블 생성되는지 확인

인덱스 최적화

- where, join, order by, group by 에서 사용되는 컬럼에 인덱스가 누락되엇는지 확인합니다
- 복합 인덱스에서 일부만 사용되거나 하는 경우로 복합키 인덱스가 유효하지 않은지 확인

쿼리 재작성

- 와일드 카드 위치 `%test`  와 같이 앞부붙에 와일드 카드가 오면 인덱스 사용이 불가
- select * 대신 필요한 컬럼만 조회한다
- where에 year(date_col) = 2024 등 함수 연산을 사용하면 인덱스를 무력화 하므로 피해야함
- 서브쿼리 대신 join으로 풀어서 작성할수 잇는지 검사
</details> 

<details> 
<summary>복합키 </summary>

두개 이상의 컬럼을 조합해 하나의 키로 만드는것, 이를 통해 데이터 중복을 방지할 수 있음 

- user_id, order_id 등으로 중복 주문 생성 방지 가능

앞쪽 컬럼이 정렬 우순선위 높음, 앞쪽 컬럼부터 범위를 좁힘 btree사용

쿼리 패턴을 보고 정하는게 좋음

a, b, c 로 정의 되었다면 (a), (a, b) 조건으로 검색할때는 인덱스 활용하지만 b, c만 단독 으로 사용하면 인덱스를 거의 사용하지 못함

가장 자주 사용되고 카디널리티가 높은 컬럼을 복합키의 가장 앞 순서에 배치하면 인덱스 활용도 높아짐

- user_id 등이 카디널리티가 높으므로 우선순위를 높이면 행을 더 좁혀서 탐색 범위가 줄어듬
</details> 

<details> 
<summary>select related, prefetch_related </summary>

셀렉트는 1:1, n:1에서 사용
프리패치는 1:n, n:m에서 사용하며 쿼리시 연결관계의 데이터도 한번에 불러와
액티브 레코드 데이터에서 속성 접근할때 추가 쿼리가 발생하지 않도록 함
</details> 

<details> 
<summary> MySQL, Postgres </summary>

mysql은 읽기 중심에 유리하고 수평 스케일에 강점이 있어 대규모 트래픽 대응에 많이 활용됨
레플리케이션 구성 마스터, 슬래이브, 읽기 전용 레플리케이션 구성하는 등
postgres는 복잡한 쿼리를 사용하여 통계, 분석할때 많이 활용되며
플러그인을 추가하여 fulltext를 사용한 검색 엔진을 구성하거나 vectordb로 활용할수있음
</details> 

<details> 
<summary>char, varchar, text</summary>

char 고정길이로 처리하고 빈공간은 패딩 처리, 읽기 빠름, 국가코드 상태값등에서 사용
varchar 가변길이로 사용한 만큼만 저장, 인덱스, 정렬에 사용할수 잇음
text 64kb까지 저장, 엄청 킨 문자열 처리에 유용, 별도 메모리에 저장됨, 저장목적으로 사용
</details> 

<details> 
<summary>timestamp, datetime</summary>

timestamp는 1970-01-01 부터 사용

데이트 타임은 입력된 내용 그대로 저장(문자열처럼), 서버 타임존과 무관하게 변환 없이 저장됨

타임스탬프는 서버타임존으로 utc로 변환해 저장, 조회시 utc를 다시 서버 타임존으로 변환
</details> 

<details> 
<summary>lock</summary>

테이블락 : ddl 작업시 테이블을 전체 잠그기, 

로우락 : 이노디비 핵심기능

- 베타락 : 쓰기 전용, for update를 사용해서 수정, 삭제 작업전에 락 걸기
- 공유락: 읽기 전용으로 공유락은 허용, 일관성있는 읽기 작업을 위해 락 걸기
- 갭략: 레코드 사이 빈 공간까지 잠금, 다른 트랜잭션이 gap에 데이터 추가하여 팬텀리드 되는 문제 막기 위해 사용, where 절에 범위 조건을 추가하여 사용
</details> 

<details> 
<summary>비관적 락</summary>

충돌이 발생한다고 가정, 먼저 잠그고 시작

select .. for update와 같이 베타락

```sql
BEGIN;
SELECT stock FROM product WHERE id = 1 FOR UPDATE;
-- 재고 검증 후 주문 처리
UPDATE product SET stock = stock - 1 WHERE id = 1;
COMMIT;
```
</details> 

<details> 
<summary>낙관적 락</summary>

충돌 드믄상황, 락을 잡지 않고 업데이트 시점에 충돌여부 체크

version, updated_at 필드를 사용해서 적합한 우선데이터인지 확인

프로필 업데이트, (충돌 적음)
```sql
UPDATE user
SET name = 'B', version = version + 1
WHERE id = 1 AND version = 3;
```
</details> 

<details> 
<summary> 오프셋 기반, 커서 기반 페이지네이션 차이</summary>

오프셋 기반: 
- offset이 커질수록 속도가 느려짐, offset + Limit 만큼 데이터 확인후 offset을 버리고 limit 수만 반환함
- 원하는 위치의 데이터를 가져올 수 있음

커서 기반
- 한 방향으로 페이지 네이션할때 유리함, offset이 없으므로 속도가 빠름
- 정렬 조건마다 커서 데이터가 변해야함 (최신순, 인기순 등등)
</details> 


<details> 
<summary> MySQL 관리 쿼리</summary>

``` sql
SHOW INDEX FROM table_name;
--- 테이블의 인덱스 목록(키명, 컬럼, 타입)을 출력. 복합 인덱스나 UNIQUE 여부 확인에 유용.

EXPLAIN SELECT 쿼리의 실행 계획(인덱스 사용, 조인 타입, rows 스캔 수)을 보여줌. 
---  'type: ALL'이면 풀 스캔으로 비효율. FORMAT=JSON으로 상세 분석.

SHOW ENGINE INNODB STATUS\G;
SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;
---  InnoDB 락 상태(트랜잭션 ID, 락 모드, 테이블/인덱스)를 출력. 대기 락은 INNODB_LOCK_WAITS 테이블로 확인. 데드락 진단 시 유용.

SHOW PROCESSLIST; 또는 SHOW STATUS LIKE 'Threads_%';
--- 활성 연결 목록(ID, 사용자, 쿼리 상태, 시간)을 보여줌. Threads_connected로 총 연결 수 확인. 장기 실행 쿼리(KILL로 종료) 식별.

SHOW TABLE STATUS LIKE 'table_name';
--- 테이블 크기, 행 수, 인덱스 수, 엔진 타입 출력. 데이터 증가 추적에 사용.

SHOW GLOBAL STATUS LIKE '%Queries%'; 
SHOW GLOBAL VARIABLES LIKE '%buffer%';
--- 쿼리 수, 버퍼 풀 히트율 등 성능 지표. QPS(Queries per second) 계산으로 부하 모니터링.
```
</details> 


<details> 
<summary>샤딩</summary>

데이터를 여러 서버로 물리적으로 분산하는 수평 스케일 기능
단일 서버 cpu/메모리 한계를 초과할경우
데이터가 너무 많아 pb급으로 초과할경우
트래픽이 지역/사용자별로 분산 가능할때 적용

- 장점: 부하분산, 수평 스케일링
- 단점: join 불가, 어플리케이션에서 해야함, 관리 복잡성, 데이터가 한 샤드로 몰릴경우 샤딩이 무의미해짐
</details>

<details> 
<summary>파티셔닝</summary>

대용량 테이블의 쿼리 성능을 위해 테이블을 여러개로 나누는 작업, 
테이블 크기가 100gb이상으로 쿼리속도가 느릴때, 
일별 로그 테이블을 range로 분할하고 이후에 오래된 파티션은 제거
hash로 user_id, 또는 range로 created_at 으로 분할

- 장점: 쿼리 성능 항샹
- 단점: 단일 서버 한계

</details> 


<details> 
<summary>레플리케이션</summary>

데이터를 여러 서버에 복제하여 저장하는 기술

- 동기식 복제: master 서버에서 데이터 커밋하기 전에 모든 slave 서버가 해당 데이터 수신하고 저장했음을 확인할때까지 기다림
    - 정합성은 최상, 그러나 트랜잭션 응답시간이 길어 성능은 좋지 않음
    - 데이터 손실, 불일치가 절대 허용되지 않는 경우 사용

- 비동기식 복제: slave서버로 데이터 전송은 비동기적으로 진행
    - 정합성 낮음, 복제 지연 발생할 수 잇고 master 장애시 slave 데이터 못 받을 수 있음
    - 성능은 좋음
    - 쓰기 성능이 중요하고 약간의 데이터 손실이 괜찮을때 사용
- 준동기식 복제: 하나 또는 지정된 slave만 동기화하고 나머지는 비동기 처리

- 마스터 슬레이브 구조: master는 쓰기 담당 slave는 읽기 담당
    - 쓰기 충돌이 없어 관리 단순, 읽기 부하 분산에 효과적
    - 쓰기 작업이 master에 집중되어 쓰기 성능 확장에 한계가 있음, 정합성 문제도 있음

- 마스터 마스터 구조: 쓰기 읽기 작업을 동시 진행 가능
    - 두 노드가 모든 작업이 가능하니 가용성 좋음
    - 데이터 충돌 문제가 발생할 수 있음, 같은 데이터를 수정할경우 복잡한 제어가 필요함

이커머스에서는 마스터 슬레이브 구조를 주로 사용한다
핵심 트랜잭션은 Master에서 진행, 데이터를 쓴 직후 데이터를 즉시 읽어야 하는 경우 (주문, 결제)

slave db복제 상태를 지속적으로 모니터링한다. seconds_behind_master 지표를 관찰한다

</details> 

---

### 파이썬

<details> 
<summary>`is`와 `==` 차이</summary>

is: id가 같은지 비교(메모리)
같은 객체인지 확인, 빠름
==: 값, 콘텐츠 비교

Deep Copy vs Shallow Copy (복잡한 리스트 복사 시 주의점)?
Shallow Copy? 상위 구조만 복사하고 내부 데이터는 참조 공유
deep copy: 모든 레벨 데이터 복사

</details> 

<details>
<summary> GIL </summary>

파이썬에서는 grobal interfreter lock으로 cpu bound 멀티스레딩에 제한이 있다.
최근 3.13 버전 이후에는 gil을 사용할지 선택할수 잇다
파이선에서 비동기 처리를위해 몇가지 방법이있다
cpu bound(복잡한계산)에서 비동기 처리가 필요하다면 멀티프로세싱을 사용한다
io bound (api, db, file)에서 비동기 처리가 필요하다면 멀티스레딩, asyncio를 사용해도 좋다
asyncio는 단일스레드에서 이벤트루프(코루틴)을 사용하여 여러 함수가 빠르게 번갈아가며 동작을 실행하는 방식이라 사용할만하다
asynio는 async, await 키워드를 사용해야 하며 동작 관련 함수들이 모두 해당 키워드가 있어야 한다
반면 멀티스레딩 패키지 사용시에는 async await이 없더라도 사용가능하지만 asyncio에 비해 메모리 사용량이 많다
둘다 io bound영역에서 활용하면 좋다

gc에서 참조 카운팅을 사용해 객체의 참조 수를 추적하고 0이 되면 메모리를 해제함 그런데 멀티스레드에서 동시에 카운트를 가감하면 충돌이 발생할수있고 원치 않게 메모리 해제되거나 해제되지 않는등 오버헤드 발생할수 잇음 그래서 한번에 하나의 스레드만 사용하도록 제한함
</details>

<details> 
<summary> GC</summary>

참조 카운팅 방식을 사용한다. 참조회수를 추적하고 참조 회수가 0이면 메모리 해제 동작 시점은 할당, 해제를 파악하여 스세솔드 정해서 동작함

세대기반 동작으로 순환참조 변수를 정리함

0세대는 가장 최근 1세대, 2세대는 살아 남은 변수들
</details> 

<details> 
<summary> 데코레이터</summary>

함수를 인자로 받아 기능을 확장하고 다시 함수를 반환하는 패턴, 로깅, 인증, 캐시에 주로 사용된다

제네레이터?
이터레이터와 비슷하며 yield를 사용하여 필요할때 데이터를 순회하여 가져오는 방식
이터레이터는 메모리에 데이터를 모드 적재하고 꺼내쓰는 방식
대용량 파일을 읽어올때 제네레이터 쓰면 메모리를 효율적으로 쓸 수 있다

뮤터블, 이뮤터블 차이?
파이썬에서 리스트, 셋, 딕트는 뮤터블이고 함수의 파라미터로 사용할때 주의가 필요하다
이뮤터블은 int, tuple, str
</details> 

---
### 웹

<details> 
<summary>헤더 사용이유</summary>

RFC 표준임
헤더는 SSL/TLS로 보호되어 body보다 안전
GET요청에서 body 사용 불가
커스텀 헤더는 X-로 사용
</details> 

<details> 
<summary>쿠키</summary>

서버가 클라이언트에 전송하는 데이터 조각(4kb이내) 
stateless한 Http프로토콜에서 상태 유지를 위해 사용함

세션관리, 사용자 추적, 분석 광고 등에 사용함
</details> 

<details> 
<summary> 브라우져에서 도메인 입력후 흐름</summary>

브라우저 사용흐름?
URL을 파싱한다.
DNS로 도메인의 IP를 찾는다.
서버와 TCP 연결을 맺는다.
HTTPS라면 TLS로 암호화 채널을 만든다.
서버에 HTTP 요청을 보낸다.
서버가 HTML 등 리소스를 응답한다.
브라우저가 HTML과 리소스를 렌더링한다.
</details> 

<details> 
<summary> TLS </summary>
tls는 ssl후속기능, https:// 가 tls를 사용하는 프로토콜
데이터 암호화 통신 내용을 암호화하고
전송중에 데이터가 변경되지 않음을 보방하고
사용자가 접속하는 서버가 신뢰할수 잇는 서버인지 확인한다
</details> 


<details> 
<summary> HTTP2 </summary>

http2는 바이너리형식의 프로토콜이며 멀티플렉싱을 지원함, 데이터를 프레임단위로 쪼개고 이를 한번에 동시다발적으로 순서상관없이 전송한다
http1의 네트워크 지연, 블로킹문제를 해결한다 또한 헤더 압축으로 중복데이터를 줄인다
</details> 

<details> 
<summary> CORS </summary>

corss origin resource sharing
cors는 브라우저영역에서 한 출처의 웹페이지가 다른 출처의 리소스에 접근하는것을 막음
다른곳의 리소스에 접근하는것을 막는것, 악의적인 탈취를 막기위해서
보통 서버에서 Access-Control-Allow-Origin 헤더를 포함하여 응답함
</details> 

<details> 
<summary> 세션, 토큰 차이</summary>

사용자 인증 정보를 처리할때 사용된다
세션은 사용자 인증정보를 백엔드에 db, redis에 저장하고 액세스 토큰을 클라이언트에 전달한다
로그인 이후 서비스 사용시 헤더에 토큰을 전달하여 인증된 사용자인지 매번 체크하게 된다
백엔드에서 관리하므로 백엔드 부담이 크다. 사용자가 1억명이면 1억개 세션을 관리해야 하는 상황이 발생할 수 있다.
반면 특정사용자가 토큰을 탈취당할경우 그 사용자의 세선 데이터만 제거하여 대응할수 잇으므로 관리가 용이하다
</details> 

<details> 
<summary> JWT</summary>

jwt 토큰 방식은 로그인 후 사용자에게 액세스 토큰을 전달하고 인증 정보를 서버에 저장하지 않는다
jwt 토큰은 헤더, 페이로드, 시그니쳐로 구성되며 헤더에는 알고리즘 정보, 페이로드에는 사용자 메타 정보(식별자, 만료일자), 시그니쳐는 헤더와 페이로드를 합쳐 암호화한 정보로 구성되며 클라이언트가 저장한다
서비스 사용시 클라이언트는 헤더에 토큰을 전달하고 서버는 토큰을 파싱하고 시그니쳐 내용이 헤더, 페이로드의 내용과 일치하는지 확인, 페이로드의 만료일자가 유효한지 확인하여 사용자를 인증한다
서버의 부담이 없는점이 장점이다 반면 사용자가 토큰 탈취시 서버에서 대응이 어렵다
대게 리프레시 토큰을 같이 운용한다. 액세스 토큰은 만료일자를 굉장히 짧게 가져가고 리프레시 토큰을 사용하여 주기적으로 재발급 받도록하여 탈취 위험을 줄인다. 리프레시 토큰은 http only 옵션을 사용하도록하여 유출 문제를 막는다
리프레시 토큰은 백엔드에 저장한다. 수명주기는 30일로 설정한다. 활성사용자는 서비스 접속시 ttl을 늘려서 불편함을 최소화하고 비활성사용자는 30일 이후 토큰을 삭제하여 서버 부담을 줄인다
</details> 

<details> 
<summary> HTTP Only</summary>

자바스크립트에서 접근 불가능하도록 하는 옵션, 서버에서만 읽을수 있도록함, 주로 리프레시 토큰이 이 옵션을 사용함
</details> 


<details> 
<summary> XSS</summary>

cross site scripting
클라이언트 사이드 취약점, 공격자가 웹 리소스에 악성 스크립트를 삽입하여 이용자의 웹 브라우저에서 해당 스크립트를 실행

</details> 

<details> 
<summary> CSRF</summary>

cross site request forgery
로그인된 사용자가 자신도 모르게 공격자가 의도한 행동을 대신 수행하도록 하는 공격기법
백엔드에서는 간단하게 refere, Host 비교만으로 검증하는것으로 기본 방어가능
csrf 토큰사용하여 방어하기도함
</details> 

---
### 아키텍쳐

<details> 
<summary>헥사고날 아키텍쳐 </summary>

도메인이 중심의 구조, 인바운드 어댑터는 api 입력등이 있고
아웃바운드 어댑터로는 인프라및 외부 api 연결등을 다루게 됩니다
또한 port 는 adapter와 연결할 인터페이스를 관리하게 됩니다
장점은 도메인 로직 독립성, 테스트 코드 유지보수성이 있으나 단점 초기 비용 높음
</details> 

<details> 
<summary>레이어드 아키텍쳐 </summary>

뷰 레이어, 애플리케이션 서비스, 도메인 서비스 로 구성되며 간단하고 직관적인 구조입니다
단점으로 도메인서비스가 인프라에 간접적으로 의존하는 상황이 발생할 수 있으며
따라서 적절한 인터페이스를 사용하여 각 영역을 추상화하여 의존도를 낮춰야 합니다
</details> 

<details> 
<summary> CQRS</summary>

커맨드와 쿼리를 분리, 즉 읽기 작업, 쓰기 작업을 분리한 패턴입니다
장점으로 쓰기 작업은 적고 읽기 작업(트래픽)이 많다면 작용을 고려해볼만 합니다
특히 대시보드를 구성할때 적합하다 생각합니다
트래픽이 비대칭하고 읽기 작업에서 복잡한 쿼리로 진행되고 다른 부분에도 영향을 준다면
읽기에 사용되는 데이터를 비정규화 형태로 저장하는 방식으로 데이터를 구성하고 읽기 작업을 분리할수 잇습니다
단점으로 데이터를 중복으로 관리해야한다는 점이고
이때 주문을 예를 들면 주문 발생시 비동기 처리로 읽기 데이터를 구성함, 주문이 많이 발생한다면
배치를 적용,그러나 배치는 주기를 설정하기따라 데이터 공백이 발생
하이브리드 방식을 사용해서 사용자가 접근하기 쉬운 데이터는 준 실시간으로 생성 처리하고
이후 데이터는 배치작업으로 동기화, 핵심은 언젠가는 동기화 된다는 점
</details> 


<details> 
<summary>이벤트 소싱 </summary>

이벤트 자체를 불변 데이터로 관리하는 방식으로 특정 시점의 데이터 상태를 정확히 확인할수 있는 장점이 있습니다
최산 상태를 구하기 위해서는 이벤트를 조합하는 방식으로 구합니다
이때 스냅샷을 적용하여 시간을 단축할 수 있습니다
전동적인 로깅과 최신상태 유지 방식은 변화된 부분에 집중하지만 이벤트 소싱은 변화 자체를 관리하므로 디버깅, 감사로그 등에 유연하게 대응할 수 있습니다
</details> 


<details> 
<summary>레포지토리 패턴 </summary>

db 쿼리작업을 담당하는 패턴으로 비즈니스 로직에서 데이터를 조작하는 작업을 분리합니다
또한 쿼리에 대한 내용을 추상화하였기에 db 엔진이 변경될경우 비즈니스 로직의 변경사항이 없는것이 장점
</details> 


<details> 
<summary> 2PC </summary>
트랜잭션을 지원하는 엔진일때 적용가능한 구조
서로 다른 노드를 코디네이터 노드가 관찰하여 트랜잭션을 관리한다
분산환경에서 원자성을 유지하려고 사용한다
코디네이터가 노드들 상태보고 커밋, 롤백을 판단한다
대기시간이 길어질수 있는게 문제, 코디네이터 노드가 문제가 될수 잇는것도 문제
트랜잭션 기능이 없는 노에스큐엘과는 사용 못함
</details> 


<details> 
<summary> 사가패턴</summary>

msa 환경에서 여러 서버간의 통신 일관성을 위해 사용되는 분산 트랜잭션 패턴
여러개 서버 통신중 하나가 실패하면
보상 코드를 실행하여 데이터 변환을 취소시켜서 원상 복구한다
보상 코드를 장성시 누락하면 데이터 불일치 상태가 될수 잇음
보상 코드 실패시 재시도 로직이 필요함
</details> 


<details> 
<summary> 아웃박스 패턴</summary>

db 트랜잭션과 비동기 처리의 일관성을 유지하기 위한 패턴으로
주문 완료 후 이메일 전송시
이메일 전송을 비동기로 처리해야 할때
해당 내용을 outbox 에 기록하고 작업을 실행하여 성공 여부를 관리한다
재시도하거나 주문을 취소하는 작업으로 이어진다
</details> 


<details> 
<summary> 서킷 브레이커</summary>

예를 들어 외부 서버 호출시 장애가 발생하여 후속 작업이 진행이 불가할때
서킷 브레이커를 발생시켜 최소한의 작업이 진행되도록 흐름을 바꾸고
사용자는 장애를 겪지 않도록 합니다
주기적으로 외부 서버 상태를 파악하여 서킷브레이커 유지 할지 말지를 판단한다
장애가 해소되어 서킷브레이커가 해제되면
최소한의 작업으로 진행된 데이터들에 대해 후속작업을 진행하여 데이터 빈약, 불일치를 추가적으로 수행하여 작업을 완료시킨다
</details> 



---
### 자료구조

<details> 
<summary>힙</summary>

우선순위 큐를 위해 만들어진 구조, 우선순위 높은 데이터가 먼저 나가는 구조
와전 이진트리,
최대힙: 부모 노드의 키값이 자식노드의 키보다 큼
최소힙: 부모 노드의 키값이 자식노드의 키보다 작음
</details> 

<details> 
<summary>스택</summary>

last in first out, 재귀호출, 되돌리기 등에 사용, dfs에서 사용할수 잇음
</details> 

<details> 
<summary>큐</summary>

first in first out, 대기열, bfs등에 사용됩니다
</details> 

<details> 
<summary>DFS, BFS</summary>

- 깊이 우선 탐색, 노드의 하위노드 순으로 탐색
- 너비 우선 탐색, 노드의 형제노드 순으로 탐색
</details> 

---
### 인프라

<details> 
<summary>카프카 </summary>

대규모 스트림, 로그처리에 유용하다
msa환경에서 이벤트 드리븐 구조에서 주로 사용되며
메시지를 읽어도 지워지지 않고 offset을 조정하여 최신 데이터를 읽어야 한다
단순 비동기 처리에 사용하기에는 오버스펙이다
pull 방식으로 컨슈머가 필요할때 적절히 읽는 방식
하나의 메세지를 여러 컨슈머 그룹에서 읽을 수 있다
주문 생성후 재고 서비스, 결제 서비스, 알림 서비스 등에서 메시지를 일어야 할때 사용

- 토픽: 이벤트를 종류별로 나누는 노리적 구분
- 파티션: 토픽을 물리적으로 나눈 조각, 병렬처리 기본 단위
- 컨슈머 그룹: 파티션을 나눠 읽기 위한 묶음, 
</details> 

<details> 
<summary>래빗엠큐 </summary>

push방식으로 컨슈머에게 데이터를 전달하는 방식이다
낮은 지연시간과 라우팅 기능이 유연하다 실시간 처리에 유리하다
실제 작업큐로 사용될때 즉 비동기 처리에 적합하다 (메일, pdf 생성)
또는 지연 큐가 필요할때 사용한다 (5분뒤 알림보내기)

- exchange 메시지를 큐에 전달하는 중게기
- queue 메시지 저장 큐
- route 익스체인지가 적절한 큐로 전달하는 규칙, 라우팅키, 바인딩키로 구성함

컨슈머가 큐 구독시 바인딩 규칙을 정함
x-dead-letter-exchange, x-dead-letter-routing-key
</details> 

<details> 
<summary>nginx </summary>

정적파일을 서빙하기 위해서
여러 서버를 운용중이라면 로드밸런스, 라우터 목적으로 사용하기 위해서
클라이언트, 서버 사이엥서 리버스 프록시 역할을 하기 위해서
ip제한, 라우팅 담당, python 서버 직접 노출을 막음
비동기, 논블로킹 처리로 스레드하나에서 수천 연결 처리
정적 콘텐츠 캐싱, gzip압축
</details> 

<details> 
<summary>프록시 </summary>

- 리버스 프록시: 클라이언트에게 직접 서버를 노출시키지않고 서버 기능을 동작하게 하는것

- 포워드 프록시: 네이버에 요청하면 포워드 프록시 서버가 대신 리소스를 받아서 클라이언트에 줌 (사내망, vpn)

</details> 

<details> 
<summary>ecs, eks, k8s </summary>

ecs는 aws에서 컨테이너 기반으로 서버를 쉽게 배포, 관리할수 있음
클러스트 서비스 컨테이너 태스크 설계되며 트래픽에 맞게 스케일링이 가능하다
ec2, 파게이트로 구성이가능하다

eks는 K8s를 aws에서 제공하는 서비스이다
ecs에 비해 초기 학습비용이 높고, msa환경에 적합하다. gcp환경의 K8s로 이식이 간편하다
k9s등으로 모니터링, 로그/ 디버깅을 쉽게 할수 있음
헬름차트 등을 사용해서 앱을 패키지화해서 재사용가능

ec2는 클라우드 컴퓨팅 서비스, 운영체제, 볼륨등 실제 컴퓨터를 대여하는 것과 유사
초기 기본 설정과 서버 사용시 로드 밸런서 연결등을 모두 관리해야함

파게이트는 서버를 직접 관리할 필요 없이 컨테이너 배포, 실행할 수 잇는 서버리스 컨테이너 서비스
cpu, 메모리만 지정하면 된다

k8s: msa 환경에서 관리할 서비스가 많아면서 운영 리소스가 급격히 커짐
- 배포 버전관리
- 스케일링 (레플리카 셋으로 간단히 파드 수 조정 가능, Hpa로 cpu, 메모리 등으로 스케일)
- 헬스 체크로 죽은 pod 재실행 가능
- 중단 없이 배포 가능 (롤링배포, 카나리)
서비스 디스커버리, 배포, 장애복구를 자동화하여 운영 복잡도를 줄여준다

</details> 

<details> 
<summary>rpc </summary>

remote procedure call
원격지 서버의 기능을 마치 해당 서버의 함수처럼 사용하는 기술 grpc가 대표적이다
protbuf라는 문법으로 함수 목록과 Request/Response 스키마를 정의하여 사용한다
grpc는 http2 + protbuf 을 사용하여 데이터 전송 속도가 매우 빠르다

- Http2 + protbuf 조합으로 빠르다, 직렬화 역직렬화 빠름, 전송 빠름
- 서버간 언어가 달라도 사용가능
- 내부 통신에 최적화
- 스트리밍 기능 필요

</details> 

<details> 
<summary>protbuf </summary>

json은 문자열이라 바이트를 많이 사용하는데 이 단점을 해결하기위해
키대신 필드 번호를 사용하고 데이터를 바이너리로 사용하여 용량을 줄인다
사람이 볼때 가독성이 떨어짐

Blue/Green: 구버전/신버전 서버를 동시에 띄우고 트래픽만 전환 (다운타임 없음, 리소스 2배).

Canary: 소수의 사용자에게만 신버전을 먼저 배포해보고 점차 늘리는 방식.

Rolling: 서버를 하나씩 순차적으로 교체.
</details> 

 
<details> 
<summary> 파게이트란?</summary>

파게이트는 서버를 직접 관리할 필요 없이 컨테이너 배포, 실행할 수 잇는 서버리스 컨테이너 서비스 cpu, 메모리만 지정하면 된다
</details> 



<details> 
<summary> reids</summary>

- 인메모리 데이터스토어, 메모리에 올려두고 사용하여 빠름
- 주로 빠른 읽기/쓰기로 캐시, 세션, 분산락, pub/sub, 큐 등에 사용
- string, hash, set, sorted set 등의 자료구조를 지원

- 캐시: db부하 줄일수 있음
- 세션, 토큰: ttl관리가 쉬움
- 메시지큐: 카프카 보다 빠름
- 카운터 랭킹: incr, zset으로 구현 가능

클러스터 환경에서 운영 복잡함
redis cluster사용시 샤딩키 주의 필요
단일 스레드 사용시 루아 스크립트 짧게 유지해야함


</details> 



---
### 운영

<details> 
<summary> 캐시 전략</summary>

- 레이지 로딩: 읽기 시 캐시 확인 없으면 db일기 후 캐시 갱신
- write-throught: 쓰기시 db, 캐시 같이 업데이트
</details> 

<details> 
<summary> 배포 방식</summary>

- Blue/Green: 구버전/신버전 서버를 동시에 띄우고 트래픽만 전환 (다운타임 없음, 리소스 2배).
- Canary: 소수의 사용자에게만 신버전을 먼저 배포해보고 점차 늘리는 방식.
- Rolling: 서버를 하나씩 순차적으로 교체.
</details>

<details> 
<summary>모니터링 지표 </summary>

에러레이트, api 별 실패, 전체 평균 실패율을 봐야한다
결제 주문 api는 별도 알림을 구성한다

응답 지연 p95, p99 레이턴시가 급증도 탐지해야 한다
검색, 주문, 장바구니, 결제 등등을 탐지한다

p95가 평소 1.5 2배 늘어난다면 문제로 본다
트래팩이 급감하거나 급증하는것도 봐야한다

인프라에서는 시피유, 메모리, 디스크, 오토스케일링 실패 여부등을 본다
디비는 커넥션, 디비락 대기, 슬로우 쿼리를 본다
캐시는 레이턴시, 메모리, 연결실패를 본다

알림기준은?
비정상 수준이 장시간 지속될때, cpu 사용률이 5분간 90% 이상 지속될때
</details> 


<details> 
<summary> 테스트 코드 커버리지</summary>

전체 코드에 대해 % 측정하기보다 상황, 기능별로 나누고 측정하겠습니다

리스크가 높은 내용에 대해 따로 측정합니다. 결제, 주문, 장바구니, 인증/ 인가
코드 복잡성이 높은 부분, 다수의 정책이 적용되어 코드가 복잡한 부분
변경이 자주일어나는 부분, 외부 서비스 호출부분 등을 나누어 측정 기준을 따로 정하겠습니다
</details> 

<details> 
<summary>오버셀링 방지 대안 </summary>

- 초기에 rdb재고를 redis에 복사
    - stock:prod1 10

- 사용자들이 결제 화면 진입하면 구매 가능한지 확인하고 레디스에 예약 정보 기록
    - stock:prod1 의 재고와 현재 구매하려는 개수를 비교하여 구매 가능한지 검사
    - 구매 가능하다면 reserve:prod1 zset에 user:{count} 같이 저장하고 stock:prod1 재고 차감
    - EXPIRY_QUEUE 에 user_id:prod_id:{expired_at} 을 저장
    - 위 내용은 원자성 유지를 위해 Lua script로 실행하거나 multi/exec로 묶어야 한다

- 사용자가 브라우저 끄거나 오랫동안 방치할경우 대응하기위해 백엔드 워커를 사용한다
- 워커는 EXPIRY_QUEUE를 탐색하고 만료된 데이터를 찾는다
- reserve:{prod_id}를 에서 만료된 데이터 제거한다
- stock:prod1의 재고도 복구한다
- 또는 결제가 정상적으로 이뤄진다면
    - reserve:prod1 의 예약 재고 제거한다
    - EXPIRY_QUEUE 해당 내용도 제거한다
</details> 

<details> 
<summary> Zero-trust </summary>

아무것도 믿을수 없다는 전제로, 보안 대응하는것

내부서비스도 안전하지 않다 모든 트래픽에 인증 인가, 적용해야 함

필요한 권한만 부여, 위치, 디바이스, 사용자 등 판단후 접근 허용
</details> 

---
### 과제 

- 리뷰 시스템

- [티켓 예약 시스템](ticket_system.md)

- [레이트 리밋 구현](rate_limit.md)

- [풀텍스트 검색 구현](full_text.md)

- [쿠폰 발급 설계](coupon.md)

- 입찰 시스템